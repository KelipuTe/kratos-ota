## 微服务架构改造方案及原型

### 简要说明

需要改造的现有业务系统的主要工作是处理 n 个用户对 m 个渠道的数据同步。简单地说，用户关联的所有渠道中的任意一个渠道的数据发生变化，都需要通知剩下的所有渠道。

现有业务系统是分布式架构，分了几个部分但是每个部分都很大。上述处理数据同步模块集中在其中一个部分，随着业务量的增加，数据同步模块迭代和部署变得愈发很困难。

现在想将数据同步模块抽出来，使用微服务架构进行改造。这里使用 kratos 框架实现了一个简易原型以验证可行性。

### 毕业项目

> 对当下自己项目中的业务，进行一个微服务改造，需要考虑如下技术点：

毕业项目的技术点在改进方案中都可以使用，但是有几个部分并不是必须的，对于现阶段的系统有些冗余。

- 微服务架构（BFF、Service、Admin、Job、Task 分模块）
  - 改造的目标系统主要是数据同步，Service、Admin、Job、Task 都是需要的，但是没有明显的 BFF 层的需求。
- API 设计（包括 API 定义、错误码规范、Error 的使用）
  - API 需要重新设计，现有系统的 API 非常混乱，重复的、不合理的 API 非常多。模块分离出来之后，基本上所有的接口都变成资源型接口了，可以使用restful风格重新定义
  - 现有系统的错误码和报错结构设计也不合理，而且没有链路追踪，debug 时非常吃力。这块准备使用 errors.wrap+链路追踪的方式，这样就可以通过报障日志，快速定位到哪个项目的哪行error，结合入口日志就可以快速还原故障场景。
  - http code 全是 200，每个请求都需要判断有没有错误码。需要重新规范 http code，什么场景使用对应的 code。
- gRPC 的使用
  - 现有接口用的都是 HTTP1.1，项目部署在内网环境效率还可以。因为上游项目没有适配 grpc，所以微服务改造后，第一阶段依然需要 grpc 和 http 并存的模式，可以先用 grpc 改造上游项目的一些有瓶颈的接口。
- Go 项目工程化（项目结构、DI、代码分层、ORM 框架）
  - 原有系统模块划分不明确，有大量重复的功能代码块。首先需要把大量重复的功能代码块整合成一个或者多个工具集，然后再根据渠道（主模块）和工具集（辅助模块）把系统各个模块完全隔离。防止渠道之间因为共用性的逻辑代码块产生耦合进而互相影响。
- 并发的使用（errgroup 的并行链路请求）
  - 原有系统的数据同步设计，基本没有使用并发。数据按渠道划分之后，全部是单线程操作，同步效率非常低，大数据量的用户经常堵队列。改进方案计划把同步任务分得更细一点，借助并发编程的思路，将同步任务进行派发，然后借助 errgroup 可以对同一数据主体的数据进行批量同步，这样应该可以大幅提升同步效率，并解决大数据量的用户阻塞队列的问题。
- 微服务中间件的使用（ELK、Opentracing、Prometheus、Kafka）
  - 原有系统没有使用中间件，全部是数据库和文件操作，导致项目模块之间耦合度非常高。改进方案使用消息中间件，将必须同步完成的数据同步和不需要同步完成的数据同步分离，目标是使用 kafka 的消息订阅，这里先用 redis 的消息订阅模拟一下。
  - 原有的日志使用文件的形式记录在本地，非常占空间。后续结合 bash 脚本，定期对文件进行压缩后，虽然解决了一点问题，但是查询又变得的困难了。改进方案使用 es 和 kibana 对数据进行采集和记录，并根据不同的优先级，定期归档和清除。
- 缓存的使用优化（一致性处理、Pipeline 优化）
  - 缓存的使用优化主要有两点：1、修改现有的野蛮的缓存结构，现在 redis 被当 memcache 用了，完全没有发挥 redis 数据结构的优势。2、将高频但碎片的数据使用缓存进行暂存和合并，降低服务器的通信压力。

因为工作原因，这些点目前只是进行了初步的设计，并没有时间全部做完。简要的实现了 Service 和 Job，用 gorm 接入 mysql，用 redis 模拟队列引擎，整个业务模型使用 DDD 的思路进行设计。主要实现了两个部分，一个是普通的 CRUD 业务的基本逻辑，一个是借助队列实现的异步的数据并发同步的基本就结构。

数据库表结构在 dbsql 目录里。时间有限，我也没有能够做好数据库迁移脚本。
